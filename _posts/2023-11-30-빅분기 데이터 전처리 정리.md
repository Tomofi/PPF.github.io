---
title : (231130) 빅분기 데이터 전처리 정리
date : 2023-11-30 11:00:00 +/09:00
categories : [Devlog, DevTip]
tags : [DevTip] #소문자만 가능
---

### 날짜: 2023-11-06 09:44
&nbsp;

### 주제: #python 

&nbsp;

----

### 메모

#### (1) 데이터 전처리 체크

##### (1-1) 01 Getting & Knowing Data

> **Q1. 데이터 로드: 데이터 \t로 구분**
> - df = pd.read_csv('https://raw.githubusercontent.com/Datamanim/pandas/main/lol.csv', **sep=\t**')

> **Q6. 6번째 컬럼의 데이터 타입을 확인**
> -  Ans = df.iloc[:,5].dtype

> **Q7. 데이터셋의 인덱스 구성**
> - df.index

> **Q9. 데이터 로드: 컬럼 한글 처리**
> - df = pd.read_csv(DataUrl, encoding='euc-kr')

> **Q11. 수치형 변수를 가진 컬럼 출력**
> - df.select_dtypes(exclude=object).columns

> **Q12. 범주형 변수를 가진 컬럼 출력**
> - df.select_dtypes(include=object).columns

> **Q13. 각 컬럼의 결측치 숫자 파악**
> - df.isnull().sum()

> **Q17. 평균 속도 컬럼의 4분위 범위(IQR)값을 구하여라**
> - df['평균 속도'].quantile(0.75) -df['평균 속도'].quantile(0.25)

> **Q18. 읍면동명 컬럼의 유일값 갯수를 출력하라**
> - df['읍면동명'].nunique()


&nbsp;

##### (1-2) Filtering & Sorting
> **Q21. quantity 컬럼 값이 3인 데이터를 추출하여 첫 5행을 출력하라**
> - Ans = df.loc[df['quantity'] == 3].head()
> - df[df['quantity'] == 3].head()

> **Q22. quantity 컬럼 값이 3인 데이터를 추출하여 index를 0부터 정렬하고 첫 5행을 출력하라**
> - df.loc[df['quantity'] == 3].head().**reset_index(drop=True)**

> **Q23. quantity, item_price 두개의 컬럼으로 구성된 새로운 데이터 프레임을 정의하라**
> - df[ [ 'quantity', 'item_price' ] ].head()

> **Q24. item_price 컬럼의 달러표시 문자를 제거하고 float 타입으로 저장하여 new_price 컬럼에 저장하라**
> - df['new_price'] = df['item_price'].**str[1:].astype('float')**

> **Q25. new_price 컬럼이 5이하의 값을 가지는 데이터프레임을 추출하고, 전체 갯수를 구하여라**
> - Ans = len(df.loc[df.new_price <=5])
> - df.loc[df['new_price'] <= 5].count()

> **Q28. df의 new_price 컬럼 값에 따라 오름차순으로 정리하고 index를 초기화 하여라**
> - df.**sort_values('new_price')**.reset_index(drop=True)

> **Q29. df의 item_name 컬럼 값 중 Chips 포함하는 경우의 데이터를 출력하라**
> - df.loc[df.item_name.str.contains('Chips')]

> **Q30. df의 짝수번째 컬럼만을 포함하는 데이터프레임을 출력하라**
> - df.iloc [ : , : : 2 ] 

> **Q33. df의 item_name 컬럼 값이 Steak Salad 또는 Bowl인 데이터를 데이터 프레임화 한 후, item_name를 기준으로 중복행이 있으면 제거하되**
> - Ans.drop_duplicates('item_name') : 첫번째 케이스만 남김
> - Ans.drop_duplicates('item_name', keep='last') : 마지막 케이스만 남김

> **Q36. df의 데이터 중 item_name의 값이 lzze 데이터를 Fizzy Lizzy로 수정하라**
> - df.loc[df.item_name == 'Izze', 'item_name'] = 'Fizzy Lizzy'

> **Q40. df의 데이터 중 choice_description 값에 Vegetables가 들어가지 않는 경우의 갯수를 출력하라.**
> - len(df.loc[~df.choice_description.str.contains('Vegetables')])

> **Q41. df의 데이터 중 item_name 값이 N으로 시작하는 데이터를 모두 출력하라**
> - df.loc[df.item_name.str[0] == 'N']
> - df.loc[df.item_name.str.startswith('N')]

> **Q42. df의 데이터 중 item_name 값의 단어갯수가 15개 이상인 데이터를 인덱싱하라**
> - df.loc[df.item_name.str.len() >= 15]

> **Q43. df의 데이터 중 new_price값이 lst에 해당하는 경우의 데이터 프레임을 구하고 그 갯수를 출력하라**
> - lst = [1.69, 2.39, 3.39, 4.45, 9.25, 10.98, 11.75, 16.98]
> - len(df.loc[df.new_price.isin(lst)])


&nbsp;

##### (1-3) Grouping

> **Q45. 데이터의 각 host_name의 빈도수를 구하고 host_name으로 정렬하여 상위 5개를 출력하라**
> - df.groupby('host_name').size().head()
> - df.host_name.value_counts().sort_index().head()

> **Q46. 데이터의 각 host_name의 빈도수를 구하고, 빈도수 기준 내림차순 정렬한 데이터 프레임을 만들어라. 빈도수 컬럼은 counts로 명명하라.**
> - Ans = df.groupby('host_name').size().\
                to_frame().rename(columns={0:'counts'}).\
                sort_values('counts',ascending=False)

> **Q47. neighbourhood_group의 값에 따른 neighbourhood 컬럼 값의 갯수를 구하여라**
> - df.groupby(['neighbourhood_group', 'neighbourhood'], as_index = False).size()

> **Q48. neighbourhood_group의 값에 따른 neighbourhood 컬럼 값 중 neighbourhood_group 그룹의 최댓값들을 출력하라**
> - ans = df.groupby(['neighbourhood_group', 'neighbourhood'], as_index = False).size()\
        .groupby(['neighbourhood_group'], as_index=False).max()

> **Q49. neighbourhood_group 값에 따른 price값의 평균,분산,최대,최소 값을 구하여라**
> - df [ [ 'neighbourhood_group', 'price' ] ].groupby('neighbourhood_group').agg(['mean', 'var', 'max', 'min'])

> **Q52. neighbourhood 값과 neighbourhood_group 값에 따른 price의 평균을 계층적 indexing 없이 구하라**
> - df.groupby(['neighbourhood', 'neighbourhood_group']).price.mean().unstack()

> **Q55. 데이터 중 neighbourhood_group 값에 따른 room_type 컬럼의 숫자를 구하고, neighbourhood_group 값을 기준으로 각 값의 비율을 구하여라**
> - Ans = df[['neighbourhood_group', 'room_type']].groupby(['neighbourhood_group', 'room_type']).size().unstack()
> - Ans.loc[:,:] = (Ans.values /Ans.sum(axis=1).values.reshape(-1,1))


##### (1-4) Apply, Map

> **Q60. Education_Level의 값중 Graduate단어가 포함되는 값은 1 그렇지 않은 경우에는 0으로 변경하여 newEduLevel 컬럼을 정의하고 빈도수를 출력하라**
> - df['newEduLevel'] = df.Education_Level.map(lambda x : 1 if 'Graduate' in x else 0)
> - Ans = df['newEduLevel'].value_counts()

> **Q62. Marital_Status 컬럼값이 Married이고 Card_Category 컬럼의 값이 Platinum인 경우 1 그외의 경우에는 모두 0으로 하는 newState컬럼을 정의하라. newState의 각 값들의 빈도수를 출력하라.**
> - def newState(x):
	    if (x.Marital_Status == 'Married') & (x.Card_Category == 'Platinum'):
	        return 1
	    else:
	        return 0
	df['newState'] = df.apply(newState, axis=1)
	df.newState.value_counts()


##### (1-5) Time Series
> **Q65. Yr_Mo_Dy을 판다스에서 인식할 수 있는 datetime64타입으로 변경하라**
> - df['Yr_Mo_Dy'] = pd.to_datetime(df['Yr_Mo_Dy'])

> **Q66. Yr_Mo_Dy에 존재하는 년도의 유일값을 모두 출력하라**
> - df.Yr_Mo_Dy.dt.year.unique()

> **Q67. Yr_Mo_Dy에 년도가 2061년 이상의 경우에는 모두 잘못된 데이터이다. 해당 경우의 값은 100을 빼서 새롭게 날짜를 Yr_Mo_Dy 컬럼에 정의하라**
> - df.Yr_Mo_Dy = df.Yr_Mo_Dy.map(lambda x: x - pd.DateOffset(years=100) if x.year >= 2061 else x)

> **Q69. weekday컬럼을 만들고 요일별로 매핑하라 ( 월요일: 0 ~ 일요일 :6)**
> - df['weekday'] = df.Yr_Mo_Dy.dt.weekday

> **Q72. 모든 결측치는 컬럼기준 직전의 값으로 대체하고 첫번쨰 행에 결측치가 있을 경우 뒤에 있는 값으로 대체하라**
> - df = df.fillna(method='ffill').fillna(method='bfill')

> **Q73. 년도 - 월을 기준으로 모든 컬럼의 평균값을 구하여라**
> - Ans = df.groupby(df.Yr_Mo_Dy.dt.to_period('M')).mean()

> **Q74. RPT 컬럼의 값을 일자별 기준으로 1차 차분하라**
> - ans = df.RPT.diff()

> **Q75. RPT와 VAL의 컬럼을 일주일 간격으로 각각 이동평균한 값을 구하여라**
> - ans = df[ [ 'RPT', 'VAL' ] ].rolling(7).mean()

> **Q77. 일자별 영어요일 이름을 dayName 컬럼에 저장하라**
> - df['dayName']  =df['(년-월-일:시)'].dt.day_name()

> **Q79. 시간이 연속적으로 존재하며 결측치가 없는지 확인하라**
> - # 시간을 차분했을 경우 첫 값은 nan, 이후 모든 차분값이 동일하면 연속이라 판단한다.
> 	- check = len(df['(년-월-일:시)'].diff().unique())
> 	- if check == 2:
> 		- Ans =True
> 	- else:
> 		- Ans = False

> **Q80. 오전 10시와 오후 10시(22시)의 PM10의 평균값을 각각 구하여라**
> - ans = df.groupby(df['(년-월-일:시)'].dt.hour).mean().iloc[[10,22], [0]]

> **Q81. 날짜 컬럼을 index로 만들어라**
> - df.set_index('(년-월-일:시)', inplace=True, drop=True)

> **Q82. 데이터를 주단위로 뽑아서 최소, 최대, 평균, 표준편차를 구하여라**
> - ans = df.resample('W').agg(['min','max','mean','std'])


##### (1-6) Pivot

> **Q83. Indicator을 삭제하고 First Tooltip 컬럼에서 신뢰구간에 해당하는 표현을 지워라**
> - df.drop('Indicator',axis=1,inplace=True)
> - df['First Tooltip'] = df['First Tooltip'].map(lambda x: float(x.split("[")[0]))
> - Ans = df

> **Q86. Dim1에 따른 년도별 사망비율의 평균을 구하여라**
> - ans2 = df.pivot_table(index='Dim1',columns='Period',values='First Tooltip',aggfunc='mean')

> **Q88. 한국 올림픽 메달리스트 데이터에서 년도에 따른 medal 갯수를 데이터프레임화 하라**
> - ans2 = df.pivot_table(index='Year', columns='Medal', aggfunc='size').fillna(0)


##### (1-7) Merge, Concat
> **Q91. **df1과 df2 데이터를 하나의 데이터 프레임으로 합쳐라**
> - total = pd.concat([df1,df2]): 마지막 행 뒤에 합

> **Q92. df3과 df4 데이터를 하나의 데이터 프레임으로 합쳐라. 둘다 포함하고 있는 년도에 대해서만 고려한다**
> - Ans = pd.concat([df3,df4],join='inner')

> **Q94. **df5과 df6 데이터를 하나의 데이터 프레임으로 merge함수를 이용하여 합쳐라. Algeria컬럼을 key로 하고 두 데이터 모두 포함하는 데이터만 출력하라**
> - Ans = pd.merge(df5,df6,on='Algeria',how='inner')


&nbsp;
### 출처(참고문헌)
* [데이터 전처리 100Q](https://www.datamanim.com/dataset/99_pandas/pandasMain.html)
 

&nbsp;



