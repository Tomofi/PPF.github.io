---
title : CH2-1-1. 아이솔레이션 포레스트
date : 2023-12-07 14:00:00 +/09:00
categories : [DevStudy, 파이썬 딥러닝으로 시작하는 이상 징후 탐지]
tags : [파이썬 딥러닝으로 시작하는 이상 징후 탐지] 
---

* **파이썬 딥러닝으로 시작하는 이상 징후 탐지** 책을 학습하며 작성한 내용입니다.

----

#### (1) 정의
> **정의**
> - 데이터 세트를 재귀적으로 분할하는 개별 트리 구조의 집합 (앙상블)
> - 비지도 이상 징후 탐지의 예

> **원리**
> - 과정이 반복될 떄마다 무작위로 특성이 선택되고 데이터는 선택한 특성의 최소값과 최대값 간에 무작위로 선택된 값을 기준으로 분할됨.
> - 전체 데이터 세트가 분할되어 포레스트에 개별 트리를 형성할 때까지 반복
> - 이상 징후: 정상 데이터 포인트보다 루트에서 훨씬 짧은 경로를 형성
> - 평균 경로 길이와 관련된 데이터 포인트 함수를 사용하여 이상 징후 점수를 찾ㅇ르 수 있다.


&nbsp;
#### (2) 이상 징후 탐지
##### 1. 코드 전체
###### 1-1. 데이터 로드
```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.ensemble import IsolationForest
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

%matplotlib Inline

path = 'kddcup.data/kddcup.data.corrected'

columns = ['duration', 'protocol type', 'service', 'flag', 'src bytes','dst bytes', 'land', 'wrong fragment', 'urgent', 'hot', 'num failed logins', 'logged in', 'num compromised', 'root shell', 'su attempted', 'num root', 'num file creations', 'num shells', 'num access files', 'num outbound cmds', 'is host login', 'is guest login', 'count', 'srv count', 'serror rate', 'srv serror rate', 'rerror rate', 'srv rerror rate', 'same srv rate', 'diff srv rate', 'srv diff host rate', 'dst host count', 'dst host srv count', 'dst host same srv rate', 'dst host diff srv rate', 'dst host same src port rate', 'dst host srv diff host rate', 'dst host serror rate', 'dst host srv serror rate', 'dst host rerror rate', 'dst host srv rerror rate', 'label']

df = pd.read_csv(path, sep=',', names=columns, index_col=None)
df.head()
```




&nbsp;
###### 1-2. 전체 데이터 프레임 필터링 (HTTP 공격과 관련된 데이터 항목만 포함, 서비스 열 삭제)
```python
df = df[df['service'] == 'http']
df = df.drop('service',axis = 1)
columns.remove('service')
df.head()
```


&nbsp;
###### 1-3. 범주형 데이터 변형: 라벨 인코딩
```python
for col in columns:
    if df[col].dtype == 'object':
        encoded = LabelEncoder()
        encoded.fit(df[col])
        df[col] = encoded.transform(df[col])
        
df.head()
```


&nbsp;
###### 1-4. df값을 섞고 훈련, 시험 및 검증 데이터 세트를 생성
```python
for f in range(0,3):
    df = df.iloc[np.random.permutation(len(df))]
    
df2 = df[:500000]
labels = df2['label']
df_validate = df[500000:]
xtr, xt, ytr, yt = train_test_split(df2, labels, test_size=0.2, random_state=42)

xv, yv = df_validate, df_validate['label']
```



&nbsp;
###### 1-5. 모델 구축
```python
isolation_forest = IsolationForest(n_estimators = 100, max_samples=256, contamination=0.1, random_state=42)
isolation_forest.fit(xtr)
```


&nbsp;
###### 1-6. 훈련된 이오솔레이션 포레스트 모델에서 이상 징후 점수를 얻고 그래프 생성
```python
anomaly_scores = isolation_forest.decision_function(xv)
plt.figure(figsize=(15,10))
plt.hist(anomaly_scores, bins=100)
plt.xlabel('Average Path Length', fontsize=14)
plt.ylabel('Number of Data Points', fontsize=14)
plt.show()
```


&nbsp;
###### 1-7. 그래프에서 선택한 임계값을 기준으로 이상 징후를 분류하고 각 포인트의 해당 레이블 세트에서 AUC 점수를 생성
```python
from sklearn.metrics import roc_auc_score

anomalies = anomaly_scores > - 0.19
matches = yv == list(encoded.classes_).index('normal.')
auc = roc_auc_score(anomalies, matches)
print(f'AUC:     {auc:.2%}')
```



&nbsp;
###### 1-8. 검증 세트 대신 시험 세트에 대해서 그래프 생성
```python
anomaly_scores = isolation_forest.decision_function(xt)
plt.figure(figsize=(15,10))
plt.hist(anomaly_scores, bins=100)
plt.xlabel('Average Path Length', fontsize=14)
plt.ylabel('Number of Data Points', fontsize=14)
plt.show()
```


&nbsp;
###### 1-9. 그래프에서 선택한 임계값을 기준으로 이상 징후를 분류하고 각 포인트의 해당 레이블 세트에서 AUC 점수를 생성 (시험세트)
```python
from sklearn.metrics import roc_auc_score

anomalies_test = anomaly_scores > - 0.19
matches = yt == list(encoded.classes_).index('normal.')
auc = roc_auc_score(anomalies_test, matches)
print(f'AUC: {auc:.2%}')
```


&nbsp;

##### 2. 아이솔레이션 포레스트 모델
```python
from sklearn.ensemble import IsolationForest

isolation_forest = IsolationForest(n_estimator = 100, max_samples=256, contamination=0.1, random_state=42)**
```
> 	- n_estimator: 포레스트에서 사용할 트리의 수, 기본값은 100
> 	- max_samples: 트리가 구축해야하는 최대 데이터 포인트 수, 기본값은 256 or 데이터 세트의 샘플 수 중 작은 값
> 	- 오염(contamination): 이상 징후/특이값으로 간주되어야 하는 전체 데이터 세트의 백분율을 추정, 기본값은 0.1
> 	- random_state: 훈련 과정 중에 사용할 난수 생성기를 초기화할 숫자


&nbsp;


### 출처(참고문헌)
* [[파이썬 딥러닝으로 시작하는 이상 징후 탐지]](https://product.kyobobook.co.kr/detail/S000001732457)

&nbsp;