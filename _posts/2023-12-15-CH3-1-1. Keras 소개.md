---
title : CH3-1-1. Keras 소개 (간단한 분류기 모델)
date : 2023-12-15 15:58:00 +/09:00
categories : [DevStudy, 파이썬 딥러닝으로 시작하는 이상 징후 탐지]
tags : [파이썬 딥러닝으로 시작하는 이상 징후 탐지] 
use_math: true
---

* **파이썬 딥러닝으로 시작하는 이상 징후 탐지** 책을 학습하며 작성한 내용입니다.

----

#### (1) 라이브러리(모듈) 가져오기

```python
import tensorflow as tf
from tensorflow import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Input
from keras.layers import Conv2D, MaxPooling2D
from keras import backend as K
import numpy as np
```


> - MNIST 데이터 세트
> 	- CNN과 같은 컴퓨터 비전 및 이미지 처리 모델 학습 시 사용하는 이미지 모음
> 	- CNN 딥러닝 아키텍처를 생성, 훈련, 평가 가능
> 	- 훈련 이미지 60,000개, 시험 이미지 10,000개 포함
> 	- 크기: 28 * 28 픽셀
> 	- 숫자 0~9의 이미


&nbsp;
#### (2) 딥러닝 활용 변수 정의 (하이퍼 파라미터)

```python
batch_size = 128  # 배치 사이즈
n_classes = 10 # 클래스 수 (0~9, 10개)
n_epochs = 15 # 에포크 수

im_row, im_col = 28, 28
```

> - 하이퍼파라미터: 훈련 과정 전에 설정되는 파라미터 
> 	- 배치: 한 번의 반복(iteration)에서 모델을 통과하는 데이터 항목의 수
> 	- 에포크(epoch): 모델을 통해 데이터 세트 전체를 한번 통과하는 것

&nbsp;
#### (3) 훈련 및 시험 데이터 세트 정의

```python
(x_train, y_train), (x_test, y_test) = mnist.load_data()
```

&nbsp;

#### (4) 훈련 이미지 확인

```python
import matplotlib.pyplot as plt
%matplotlib inline

plt.imshow(x_train[0], cmap='gray')
plt.show()
```


&nbsp;

#### (5) 특정 클래스(1)에 대한 예제 이미지 표시

```python
fig = plt.figure(figsize=(15,10))

i = 0
for f in range(0, y_train.shape[0]):
    if (y_train[f] == 1 and i< 10):
        plt.subplot(2,5, i+1)
        plt.imshow(x_train[f], cmap='gray')
        plt.xticks([])
        plt.yticks([])
        i = i+1
        
plt.show()
```

&nbsp;
	
#### (6) 훈련 및 시험 데이터 세트 형태

```python
print(f'x_train: {x_train.shape}')
print(f'y_train: {y_train.shape}')
print(f'x_test: {x_test.shape}')
print(f'y_test: {y_test.shape}')

# x_train: (60000, 28, 28)
# y_train: (60000,)
# x_test: (10000, 28, 28)
# y_test: (10000,)
```

&nbsp;

#### (7) 채널이 먼저인지 여부에 따라 훈련 및 시험 데이터 세트를 다시 구성한 다음 모델의 입력 형태를 정의하는 코드

```python
if K.image_data_format() == 'channels first':
    x_train = x_train.reshape(x_train.shape[0], 1, im_row, im_col)
    x_test = x_test.reshape(x_test.shape[0], 1, im_row, im_col)
    input_shape = (1, im_row, im_col)
else: # 채널이 맨 뒤
    x_train = x_train.reshape(x_train.shape[0], im_row, im_col, 1)
    x_test = x_test.reshape(x_test.shape[0], im_row, im_col, 1)
    input_shape = (im_row, im_col, 1)
```

> - 모델을 훈련하기 위해 이 형태를 (60000, 28, 28, 1), (10000, 28, 28, 1)로 확장하고자 함

> - 컬러 이미지
> 	- 3차원
> 	- 행 * 열 * 채널 / 채널 * 행 * 열
> 	- 채널 값: 3 (RGB값을 알고 싶기에)

> - 그레이 스케일 이미지
> 	- 2차원
> 	- 행 * 열
> 	- 채널 값: 1


&nbsp;

#### (8) x값(float32 변환, 최소-최대 정규화), y값(원핫인코딩)

```python
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255

y_train = keras.utils.to_categorical(y_train, n_classes)
y_test = keras.utils.to_categorical(y_test, n_classes)
```

> - 정규화(특성 스케일링): 데이터 크기를 더 작고 관리하기 쉬운 값으로 재조정하려는 것

> - 최소-최대 정규화(min-max normalization)
> 	- $x^` =$  $x-x_{min} \over x_{max} - x_{min}$

> - 평균 정규화(mean normalization)
> 	- $x^` =$  $x-x_{average} \over x_{max} - x_{min}$

> - 표준화(z-score 정규화)
> 	- $x^` =$  $x-\bar{x} \over \sigma$

> - 단위 길이 조정
> 	- $x^` =$  $x \over \lVert x \rVert$

&nbsp;
> - keras.utils.to_categorical(): 원핫인코딩

&nbsp;

#### (9) 변환된 데이터 형태 출력

```python
print(f'x_train: {x_train.shape}')
print(f'x_test: {x_test.shape}')
print(f'input_shape: {input_shape}')
print(f'# of training samples: {x_train.shape[0]}')
print(f'# of testing samples: {x_test.shape[0]}')

# x_train: (60000, 28, 28, 1)
# x_test: (10000, 28, 28, 1)
# input_shape: (28, 28, 1)
# # of training samples: 60000
# # of testing samples: 10000
```

&nbsp;

#### (10) 딥러닝 모델 정의 및 층 추

```python
model = Sequential()
model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=input_shape))
model.add(Conv2D(64, (3,3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(128, activation='relu')) # 첫번째 층: 노드 128개, 활성화함수(relu) 
model.add(Dropout(0.5))
model.add(Dense(n_classes, activation='softmax')) # 두번째 층: 노드 10개, 활성화함수(softmax)

model.compile(loss=keras.losses.categorical_crossentropy, \
              optimizer=keras.optimizers.Adam(), metrics=['accuracy'])

model.summary()
```
&nbsp;
> ![그래프](/assets/img/DevStudy/케라스 모델 정의 결과.png)


> **순차 모델(sequential model)**
> - 층 스택

> **Conv2D: 2차원 합성곱 층(convolution layer)**
> - 합성곱 신경망(convolutional neural network)
> 	- 합성곱 층: 데이터를 필터링하고 각 값에 필터의 가중치를 요소별로 곱한 후 합산하여 하나의 값을 생성
> 	- 활성화 맵(=특성 맵): 픽셀 위로 필터가 움직이면서 만들어지는 더 작은 층
> 	- 커널(=필터): 이미지를 지나면서 n * n 영역의 값을 원소별로 곱해서 합산
> 	- n * n 필터, m * m 이미지: 특성 맵의 차원은 m-n+1 * m-n+1 차원 이미지가 됨

> **MaxPooling2D**
> - 최대 풀링(max pooling)
> 	- 입력 데이터가 필터(pool_size=(2,2))에 의해 스캔되고, 이미지의 2 * 2 영역의 최대값은 새로운 n차원 이미지의 값으로 선택되는 곳
> - 스트라이드 길이(stride length): 
> 	- 필터가 얼마나 이동해야하는지, 특성 맵 크기를 결정하는 역할
> 	- 지정되지 않은 경우 기본적으로 케라스는 풀(pool) 크기를 선택
> - 풀링 층
> 	- 데이터 크기를 줄여 더 쉬운 연산을 가능하게 함
> 	- 각 영역의 최대값이 선택되어 패턴이 더 두드러지기 때문에 패턴 식별에 도움이 됨

> **드롭아웃(Dropout)**
> - 무작위로 선택된 노드의 비율(파라미터로 전달)만큼 훈련 과정에서 드롭되거나 무시되는 정규화 기법

> **플래튼(flatten)**
> - 전체 입력이 한 차원으로 압축되는 층

> **밀집 층(dense layer)**
> - 단순히 인공 신경망 예제와 유사한 일반 노드 층
> - 1번째 층: 128개, 2번째 층: 10개
> - 활성화 함수
> 	- ReLu, softmax
> - 옵티마이저
> 	- Adam

&nbsp;


#### (11) 모델 훈련 및 평가

```python
from keras.callbacks import ModelCheckpoint

# 체크 포인트 생성 (모델 저장)
checkpoint = ModelCheckpoint(filepath='logs/keras_MNIST_CNN.h5', verbose=0, save_best_only=True)

# 모델 훈련
model.fit(x_train, y_train,\
         batch_size=batch_size,\
         epochs = n_epochs,\
         verbose=1, validation_data=(x_test,y_test),\
         callbacks=[checkpoint])

# 모델 평가
score = model.evaluate(x_test, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy: ', score[1])

```

> - checkpoint: 모델을 keras_MNIST_CNN.h5라는 이름으로 폴더에 저장함

&nbsp;

#### (12) AUC 점수 확인 (시험 세트 기준)

```python
from sklearn.metrics import roc_auc_score

# model = model.load_weight('logs/keras_MNIST_CNN.h5')
preds = model.predict(x_test)
auc = roc_auc_score(np.round(preds), y_test)
print(f'AUC: {auc:.2%}')
# AUC: 99.64% (좋은 점수)
```



&nbsp;

#### (13) 실제 결과 확인

```python
preds = model.predict(x_test)
print(f'predictions for x_test[0]: {preds[0]}')
print(f'Actual label for x_test[0]: {y_test[0]}')
print(f'predictions for x_test[0] after rounding: {np.round(preds)[0]}')
```


&nbsp;
#### (14) 결론

> - 이미지가 합성곱 층을 통과하면
> 	- 차원이 감소
> 	- 패턴이 더욱 뚜렷해짐
> 	- 이미지가 제대로 보이지 않을 수 있지만, 모델은 원본 이미지에서 이러한 패턴을 식별하고 이를 바탕으로 예측함.

&nbsp;

## 출처(참고문헌)
* [[파이썬 딥러닝으로 시작하는 이상 징후 탐지]](https://product.kyobobook.co.kr/detail/S000001732457)

&nbsp;